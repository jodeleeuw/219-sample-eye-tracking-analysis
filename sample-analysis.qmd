---
title: Eye tracking during feature and conjunction search
author: Josh de Leeuw
format:
  typst
knitr:
  opts_chunk:
    dev: "ragg_png"
---

# Introduction

In visual search tasks...

# Methods

```{r}
#| label: Load libraries
#| include: false

library(dplyr)
library(tidyr)
library(ggplot2)
library(osfr)
library(jsonlite)
library(purrr)
```

```{r}
#| label: Download data
#| include: false

# Downloads all .json files from OSF repo: https://osf.io/fes78/overview
osf_retrieve_node("fes78") |>
  osf_ls_files(pattern=".json", n_max=Inf) |>
  osf_download(conflicts = "overwrite")
```

```{r}
#| label: Load data into data frame
#| include: false

data <- list.files(pattern=".json") |>
  lapply(fromJSON) |>
  bind_rows()
```

```{r}
#| label: Extract data from visual search trials
#| include: false
visual_search_data <- data |>
  filter(task=="visual_search", is_practice == FALSE) |>
  select(subject, trial_index, set_size, search_type, target_present, rt, correct, tobii_data, item_positions)
```

## Participants

```{r}
#| label: Count number of subjects
#| include: false
n_subjects <- visual_search_data |>
  pull(subject) |>
  unique() |>
  length()
```

`r n_subjects` participated in the experiment in exchange for the experimenter's next born child.

## Procedure

# Results

## Behavioral

```{r}
#| label: Compute accuracy
#| include: false
accuracy_summary_data <- visual_search_data |>
  group_by(subject) |>
  summarize(accuracy = mean(correct)*100)

overall_accuracy <- mean(accuracy_summary_data$accuracy)
overall_accuracy_sd <- sd(accuracy_summary_data$accuracy)
```

Participants responded correctly on `r overall_accuracy`% of trials (*SD* = `r overall_accuracy_sd`).

```{r}
#| label: Calculate RTs by condition
#| include: false
visual_search_summary_data <- visual_search_data |>
  filter(correct==TRUE) |>
  group_by(subject, set_size, search_type, target_present) |>
  summarize(M=mean(rt))
```

```{r}
#| label: fig-behavioral-data
#| echo: false
#| message: false
#| fig-cap: Response times for visual search task. Feature search was faster than conjunction search. Performance in feature search was consistent across set size, while performance slowed as set size increased in conjunction search.

ggplot(visual_search_summary_data, aes(color=target_present, x=set_size, y=M)) +
  facet_wrap("search_type", labeller=as_labeller(c(conjunction="Conjunction Search", feature="Feature Search")))+
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(x="Set size", y="Response time (ms)", color="Target present?")+
  scale_color_manual(values=c("#4b37baff", "#c22b4cff"), labels=c("No", "Yes")) +
  scale_x_continuous(breaks=c(4,8,16,32))+
  theme_bw()+
  theme(panel.grid=element_blank(), legend.position = "bottom")
```

## Eye tracking

```{r}
#| label: Extract eye tracking dataframe
#| include: false
eye_tracking_data <- visual_search_data |>
  unnest(tobii_data) |>
  select(-leftPupilDiameter, -rightPupilDiameter) |>
  mutate(x=1920*x, y=1080*y)
```

```{r}
#| label: Algorithm for fixation detection
#| include: false

# this algorithm was introduced by Engbert & Kliegl (2003)
# https://doi.org/10.1016/s0042-6989(03)00084-1

compute_fixations <- function(data) {

  sampling_interval <- median(diff(data$timestamp))

  # compute velocity over 5 points. looks 2 points back and 2 points forward.
  # this reduces the influence 
  d <- data |>
    mutate(vx = (lead(x, 2) + lead(x, 1) - lag(x, 1) - lag(x, 2))/(6*sampling_interval)) |>
    mutate(vy = (lead(y, 2) + lead(y, 1) - lag(y, 1) - lag(y, 2))/(6*sampling_interval)) |>
    filter(!is.na(vx), !is.na(vy))

  # compute standard deviation of x and y components of velocity,
  # but uses medians instead of means.
  sigma_x <- sqrt(median(d$vx^2) - median(d$vx)^2)
  sigma_y <- sqrt(median(d$vy^2) - median(d$vy)^2)

  # free parameter. larger lambda values result in higher thresholds for saccade.
  lambda <- 6

  thresh_x <- lambda * sigma_x
  thresh_y <- lambda * sigma_y

  # this basically creates an ellipse in 2d velocity space, centered at (0,0)
  # points that fall outside the ellipse are saccades.
  d <- d |>
    mutate(is_saccade = (vx / thresh_x)^2 + (vy / thresh_y)^2 > 1)

  # creates a column of event labels. if the current value for is_saccade is the 
  # same as the previous value, the event id will stay the same. otherwise
  # it will increase by 1. this lets us group together fixations and saccades.
  d <- d |>
    mutate(event = cumsum(is_saccade != lag(is_saccade, default=first(is_saccade))))

  # take the whole timeseries and reduce it down into events, computing some
  # summary statistics for the event. removes the saccade events and keeps the fixations.
  fixations <- d |>
    group_by(event) |>
    summarize(
      is_saccade = first(is_saccade),
      x = median(x),
      y = median(y),
      start = first(timestamp),
      end = last(timestamp),
      duration = last(timestamp) - first(timestamp),
      n_samples = n()
    ) %>%
    filter(!is_saccade)

  return(fixations)
}
```

```{r}
#| label: Extract item locations for each trial
#| include: false

item_locations <- eye_tracking_data|>
  select(subject, trial_index, search_type, set_size, target_present, item_positions) |>
  group_by(subject, trial_index, search_type, set_size, target_present) |>
  slice_head(n=1) |>
  unnest(item_positions)
```

```{r}
#| label: Compute fixations
#| include: false

fixations <- eye_tracking_data |>
  group_by(subject, trial_index, search_type, set_size, target_present) |>
  reframe(compute_fixations(pick(everything())))
```


```{r}
#| label: fig-sample-trials
#| echo: false
#| fig-cap: "Sample trials from each condition. Clockwise from top left: (1) conjunction search, target absent, (2) conjunction search, target present, (3) feature search, target present, (4) feature search, target absent."

subject_id <- "8zm47yrysdzg"
trials <- c(89,86,50, 53)

subject_id <- eye_tracking_data |> 
  pull(subject) |>
  unique() |> 
  first()

trials <- eye_tracking_data |> 
  filter(subject==subject_id) |>
  group_by(search_type, target_present) |>
  slice_head(n=1) |>
  pull(trial_index)

sample_eye_movements <- eye_tracking_data |>
  filter(subject==subject_id, trial_index %in% trials)

sample_fixations <- fixations %>%
  filter(subject==subject_id, trial_index %in% trials)

sample_items<- item_locations %>%
  filter(subject==subject_id, trial_index %in% trials)

ggplot(sample_items, aes(x=x, y=y)) +
  geom_point(size=3, stroke=1, mapping=aes(color=color, shape=shape)) +
  geom_point(data=sample_eye_movements, size=1, shape="circle", color="grey70") +
  geom_point(data=sample_fixations, size=10, shape="circle open", color="white") +
  geom_path(data=sample_fixations, color="white", arrow=arrow())+
  facet_grid(
    rows=vars(search_type),
    cols=vars(target_present)
  ) +
  coord_cartesian(xlim=c(0,1920), ylim=c(0, 1080), ratio=1) +
  scale_y_reverse() + 
  scale_color_manual(values=c("#0D47A1", "#E53935"), guide="none")+
  scale_shape_manual(values=c("circle open", "cross"), guide="none")+
  theme_void()+
  theme(
    panel.border = element_rect(color="black", linewidth=3, fill=NA),
    panel.background = element_rect(fill="grey50"),
    strip.text = element_blank()
  )
```


### Number of fixations

```{r}
#| label: Count fixations per trial
#| include: false

fixation_counts <- fixations |>
  group_by(subject, trial_index, search_type, set_size, target_present) |>
  summarize(n_fixations = n())
```

```{r}
#| label: fig-fixation-counts
#| echo: false
#| warning: false
#| fig-cap: Fixation 

ggplot(fixation_counts, aes(x=set_size, y=n_fixations, color=target_present)) +
  facet_wrap("search_type", labeller=as_labeller(c(conjunction="Conjunction Search", feature="Feature Search")))+
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(x="Set size", y="Number of Fixations", color="Target present?")+
  scale_color_manual(values=c("#4b37baff", "#c22b4cff"), labels=c("No", "Yes")) +
  scale_x_continuous(breaks=c(4,8,16,32))+
  theme_bw()+
  theme(panel.grid=element_blank(), legend.position = "bottom")
```

### Functional visual field

Algorithm is:
1. create radius around each fixation point in target present trials.
2. expand radius until it contains 50% of all items on the screen.
3. that is FVF for that trial


```{r}
#| label: Functional visual field analysis functions
#| include: false

find_fvf <- function(fixations_trial, items_trial, 
                     radii = seq(10, 1200, by = 5)) {
  
  # Extract coordinates as matrices (compute once)
  item_x <- items_trial$x
  item_y <- items_trial$y
  fix_x <- fixations_trial$x
  fix_y <- fixations_trial$y
  
  # Compute full distance matrix ONCE: items Ã— fixations
  dist_matrix <- sqrt(
    outer(item_x, fix_x, `-`)^2 + 
    outer(item_y, fix_y, `-`)^2
  )
  
  # Early stopping search
  for (r in radii) {
    # For each item (row), is ANY fixation within radius?
    coverage <- mean(rowSums(dist_matrix <= r) > 0)
    if (coverage >= 0.5) {
      return(r)
    }
  }
  
  return(max(radii))
}

```


```{r}
#| label: Compute FVF
#| include: false

nested_items <- item_locations |>
  group_by(subject, trial_index, search_type, set_size, target_present) |>
  nest() |>
  rename(item_locations = data)

nested_fixations <- fixations |>
  group_by(subject, trial_index, search_type, set_size, target_present) |>
  nest() |>
  rename(fixations = data)

fvf_data <- nested_items |>
  left_join(nested_fixations, by=c("subject", "trial_index", "search_type", "set_size", "target_present"))

fvf_result <- fvf_data |>
  filter(target_present == FALSE) |>
  mutate(fvf = map2_dbl(fixations, item_locations, find_fvf)) %>%
  #unnest_wider(fvf) |>
  select(-item_locations, -fixations)
```

```{r}
#| label: fig-fvf
#| fig-cap: Functional visual field estimates for feature and conjunction search.
#| echo: false

ggplot(fvf_result, aes(x=set_size, y=fvf))+
    facet_wrap("search_type", labeller=as_labeller(c(conjunction="Conjunction Search", feature="Feature Search")))+
  geom_point()+
  geom_smooth(method="lm", formula="y~log(x)") +
  labs(x="Set size", y="Function Visual Field (px)")+
  scale_x_continuous(breaks=c(4,8,16,32))+
  theme_bw()+
  theme(panel.grid=element_blank(), legend.position = "bottom")
 
```

# Notes on things to fix in the data

1. there's no pixel-level eye tracking. it is in normalized coords.
2. three timestamps feels excessive. figure out which one should be included.